# Adobe Techverse 2025 â€“ Challenge 1B  

This project implements a smart document analysis system that extracts and ranks the most relevant sections from a collection of PDF documents. The system is guided by a given **persona** and their **job-to-be-done**, ensuring the output is aligned with user intent.

---

## ğŸš€ Key Features

- âœ… Persona- and job-aware section extraction
- ğŸ“‘ Uses structured outlines from Round 1A when available
- ğŸ” TF-IDF and keyword-based relevance scoring
- âœ‚ï¸ Granular sub-section refinement using top sentence extraction
- âš™ï¸ Fully offline â€” no internet required during execution
- ğŸ§  Generalizable across domains (research, business, education, travel, etc.)
- ğŸ“„ JSON output matches `challenge1b_output.json` specification

---

## ğŸ—‚ Folder Structure

```

techverse\_round\_1b/
â”‚
â”œâ”€â”€ Collection\_X/                # Input/output for a document set
â”‚   â”œâ”€â”€ PDFs/                    # Input PDFs
â”‚   â”œâ”€â”€ challenge1b\_input.json   # Persona, job, input metadata
â”‚   â””â”€â”€ challenge1b\_output.json  # Final ranked result (generated)
â”‚
â”œâ”€â”€ schema/                      # (Optional) output format schema
â”œâ”€â”€ src/
â”‚   â””â”€â”€ analyze\_collections.py   # Main processing script
â”‚
â”œâ”€â”€ requirements.txt             # Python package requirements
â”œâ”€â”€ Dockerfile                   # For containerized execution
â””â”€â”€ approach\_explaination.md     # Explanation of the methodology

````

---

## ğŸ› ï¸ Setup & Execution

### âš™ï¸ Local Python Setup

> ğŸ’¡ Python 3.10+ is required.

```bash

# (Optional) create virtual environment
python -m venv venv
source venv/bin/activate  # For Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the processing script
python src/analyze_collections.py --root .
````

---

### ğŸ³ Docker Build & Run (Offline-Compatible)

```bash
# Build Docker image (inside techverse_round_1b)
docker build -t techverse-1b .

# Run the container (Linux/macOS)
docker run --rm -v $PWD:/app techverse-1b --root /app

# Run on Windows CMD
docker run --rm -v %cd%:/app techverse-1b --root /app
```

---

## ğŸ“¤ Output Format

The system generates `challenge1b_output.json` in each `Collection_X/` folder. It contains:

* **Metadata**: Persona, job, input documents, and timestamp
* **Extracted Sections**: Section titles with page number and importance rank
* **Subsection Analysis**: Refined sentences providing focused insights

---

## ğŸ“Œ Constraints Met

* âœ… CPU-only execution
* âœ… No internet access
* âœ… Model size < 1GB
* âœ… Execution time < 60 seconds (3â€“5 PDFs)

---

## ğŸ“„ Methodology

The complete methodology, including segmentation logic, ranking heuristics, TF-IDF scoring, and fallback strategies, is explained in detail in the `approach_explaination.md` file provided in the `src/` directory.

---

## âœ… Example Use Cases

* ğŸ§ª Researcher preparing literature reviews
* ğŸ“Š Analyst comparing financial trends
* ğŸ“š Student identifying exam topics
* âœˆï¸ Travel planner building itinerary insights

---

## â„¹ï¸ Note

If outline JSONs from Round 1A are present, they are used for accurate section segmentation. In their absence, regex- and heuristic-based segmentation ensures robustness across formats.

